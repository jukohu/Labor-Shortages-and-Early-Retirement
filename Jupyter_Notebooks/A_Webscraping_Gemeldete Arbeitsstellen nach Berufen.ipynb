{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping Data on Arbeitstellen from the website of the BA\n",
    "\n",
    "This code automatically downloads all excel files (2020-2025) and all pdf files (pre 2020) from the BA's website, extracts the relevant tables from the files and merges them together in one usable data frame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to load the relevant packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\jhummels\\appdata\\roaming\\python\\python313\\site-packages (4.31.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\jhummels\\appdata\\roaming\\python\\python313\\site-packages (2.2.3)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\jhummels\\appdata\\roaming\\python\\python313\\site-packages (3.1.5)\n",
      "Requirement already satisfied: requests in c:\\users\\jhummels\\appdata\\roaming\\python\\python313\\site-packages (2.32.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement os (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for os\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium pandas openpyxl requests os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Step: Automized download of all excel files (February 2020 - February 2025) from the BA website (https://statistik.arbeitsagentur.de/SiteGlobals/Forms/Suche/Einzelheftsuche_Formular.html?topic_f=analyse-gemeldete-arbeitsstellen-kldb2010)\n",
    "\n",
    "In the code I first browse through all pages of the website and search for links that end with 'xls' or 'xlxs' indicating excel files and then I store all links. Then, I execute those links and download all excel files and save them in the same folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Packages ===\n",
    "\n",
    "from selenium import webdriver # Selenium is used for the automatic download of files from the web browser\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os\n",
    "import requests\n",
    "import urllib.parse\n",
    "import time\n",
    "\n",
    "# === Setup Edge ===\n",
    "\n",
    "# The microsoft edge driver is required for selenium to work. This code opens the microsoft edge driver:\n",
    "service = Service(\"C:\\\\Users\\\\jhummels\\\\OneDrive - DIW Berlin\\\\Gehlen, Annica's files - retirement-labor-shortages\\\\edgedriver\\\\msedgedriver.exe\")\n",
    "options = webdriver.EdgeOptions()\n",
    "options.add_argument(\"start-maximized\")\n",
    "driver = webdriver.Edge(service=service, options=options)\n",
    "\n",
    "# === Opening Ergebnisseite ===\n",
    "\n",
    "# This command opens the BA's website from which we want to download all the excel sheets \n",
    "driver.get(\"https://statistik.arbeitsagentur.de/SiteGlobals/Forms/Suche/Einzelheftsuche_Formular.html?topic_f=analyse-gemeldete-arbeitsstellen-kldb2010\")\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "# === Accepting Cookie-Banner ===\n",
    "\n",
    "# If we don't deal with the cookies window that automatically opens when opening the website link, our webscraping will not work. The following code adresses \n",
    "# this problem. However, the command still has issues with accepting cookies by itself, so when the cookie window opens you have to manually accept cookies and then the code will run errorless. Except for \n",
    "# accepting cookies, you shoule not do anything in the window while the code is running. Once the command is executed, the window should close automatically. \n",
    "try:\n",
    "    cookie_button = wait.until(EC.element_to_be_clickable((By.ID, \"cc-all\")))\n",
    "    cookie_button.click()\n",
    "    print(\"‚úÖ Cookies akzeptiert.\")\n",
    "    time.sleep(2)\n",
    "except:\n",
    "    print(\"‚ÑπÔ∏è Kein Cookie-Banner gefunden oder schon geschlossen.\") # This is the response you will get if you accept cookies manually, which you have to do. \n",
    "\n",
    "# === Navigation through all subpages and collection of all Excel-Links ===\n",
    "\n",
    "# The following code browses through all subpages on the website and obtains all links, which initiate the download of excel files\n",
    "\n",
    "all_excel_links = []\n",
    "page_number = 1\n",
    "\n",
    "while True:\n",
    "    print(f\"\\nüîÑ Lade Seite {page_number}...\")\n",
    "\n",
    "    try:\n",
    "        wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//a[contains(@href, '.xls')] | //a[contains(@href, '.xlsx')]\")))\n",
    "    except:\n",
    "        print(\"‚ùå Keine Excel-Links gefunden auf dieser Seite.\")\n",
    "        break\n",
    "\n",
    "    elements = driver.find_elements(By.XPATH, \"//a[contains(@href, '.xls')] | //a[contains(@href, '.xlsx')]\")\n",
    "    for el in elements:\n",
    "        href = el.get_attribute(\"href\")\n",
    "        if href and href not in all_excel_links:\n",
    "            all_excel_links.append(href)\n",
    "\n",
    "    # Searching for next subtab and press 'next'\n",
    "    try:\n",
    "        next_link = driver.find_element(By.XPATH, \"//a[contains(@class, 'forward') and contains(@class, 'button')]\")\n",
    "        ActionChains(driver).move_to_element(next_link).perform()\n",
    "        next_link.click()\n",
    "        time.sleep(2)\n",
    "        page_number += 1\n",
    "    except:\n",
    "        print(\"‚úÖ Keine weitere Seite gefunden oder Button deaktiviert.\")\n",
    "        break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# === Printing all Excel-Links ===\n",
    "print(f\"\\nüîó Insgesamt {len(all_excel_links)} Excel-Dateien gefunden.\")\n",
    "\n",
    "# === Preparing Download-Folder ===\n",
    "os.makedirs(r\"C:\\Users\\jhummels\\OneDrive - DIW Berlin\\GEHLEN~1\\Data\\BA_data\\A_GEME~1\\ARBEIT~1\", exist_ok=True)\n",
    "failed_links = []\n",
    "\n",
    "# === Hilfsfunktion: Retry-Logik ===\n",
    "def download_with_retries(url, retries=3, delay=5):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=20)\n",
    "            if response.status_code == 200:\n",
    "                return response\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Versuch {i+1} fehlgeschlagen f√ºr {url}: {e}\")\n",
    "            time.sleep(delay)\n",
    "    return None\n",
    "\n",
    "# === Download Excel-Files ===\n",
    "for link in all_excel_links:\n",
    "    filename = link.split(\"/\")[-1].split(\"?\")[0].split(\";\")[0]\n",
    "    filename = urllib.parse.unquote(filename)\n",
    "    filepath = os.path.join(r\"C:\\Users\\jhummels\\OneDrive - DIW Berlin\\GEHLEN~1\\Data\\BA_data\\A_GEME~1\\ARBEIT~1\", filename)\n",
    "\n",
    "    # Falls Datei schon existiert, √ºberspringen\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"‚è© √úberspringe bereits vorhandene Datei: {filename}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"‚¨áÔ∏è Lade herunter: {filename}\")\n",
    "    response = download_with_retries(link)\n",
    "    if response:\n",
    "        try:\n",
    "            with open(filepath, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"‚úÖ Erfolgreich gespeichert: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Fehler beim Speichern von {filename}: {e}\")\n",
    "            failed_links.append(link)\n",
    "    else:\n",
    "        print(f\"‚ùå Endg√ºltig fehlgeschlagen: {filename}\")\n",
    "        failed_links.append(link)\n",
    "\n",
    "# === Safe all failed links ===\n",
    "if failed_links:\n",
    "    with open(\"failed_excels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for link in failed_links:\n",
    "            f.write(link + \"\\n\")\n",
    "    print(f\"\\n‚ö†Ô∏è {len(failed_links)} Dateien konnten nicht geladen werden. Gespeichert in 'failed_excels.txt'\")\n",
    "else:\n",
    "    print(\"\\nüéâ Alle Excel-Dateien erfolgreich heruntergeladen!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Step: Automized download of all pdf files (October 2011 - February 2020) from the BA website (https://statistik.arbeitsagentur.de/SiteGlobals/Forms/Suche/Einzelheftsuche_Formular.html?topic_f=analyse-gemeldete-arbeitsstellen-kldb2010)\n",
    "\n",
    "I use the same procedure as for the download of Excel file just that here I am looking for links ending with 'pdf'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Packages ===\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os\n",
    "import requests\n",
    "import urllib.parse\n",
    "import time\n",
    "\n",
    "# === Edge Setup ===\n",
    "service = Service(\"C:\\\\Users\\\\jhummels\\\\OneDrive - DIW Berlin\\\\Gehlen, Annica's files - retirement-labor-shortages\\\\edgedriver\\\\msedgedriver.exe\")\n",
    "options = webdriver.EdgeOptions()\n",
    "options.add_argument(\"start-maximized\")\n",
    "driver = webdriver.Edge(service=service, options=options)\n",
    "\n",
    "# === Ergebnisseite √∂ffnen ===\n",
    "driver.get(\"https://statistik.arbeitsagentur.de/SiteGlobals/Forms/Suche/Einzelheftsuche_Formular.html?topic_f=analyse-gemeldete-arbeitsstellen-kldb2010\")\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "\n",
    "# === Cookies akzeptieren ===\n",
    "try:\n",
    "    cookie_button = wait.until(EC.element_to_be_clickable((By.ID, \"cc-all\")))\n",
    "    cookie_button.click()\n",
    "    print(\"‚úÖ Cookies akzeptiert.\")\n",
    "    time.sleep(2)\n",
    "except:\n",
    "    print(\"‚ÑπÔ∏è Kein Cookie-Banner gefunden oder schon geschlossen.\")\n",
    "\n",
    "# === Sammeln aller PDF-Links von allen Seiten ===\n",
    "all_pdf_links = []\n",
    "page_number = 1\n",
    "\n",
    "while True:\n",
    "    print(f\"\\nüîÑ Lade Seite {page_number}...\")\n",
    "\n",
    "    try:\n",
    "        wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//a[contains(@href, '.pdf')]\")))\n",
    "    except:\n",
    "        print(\"‚ùå Keine PDF-Links gefunden auf dieser Seite.\")\n",
    "        break\n",
    "\n",
    "    elements = driver.find_elements(By.XPATH, \"//a[contains(@href, '.pdf')]\")\n",
    "    for el in elements:\n",
    "        href = el.get_attribute(\"href\")\n",
    "        if href and href not in all_pdf_links:\n",
    "            all_pdf_links.append(href)\n",
    "\n",
    "    # Weiterbl√§ttern\n",
    "    try:\n",
    "        next_link = driver.find_element(By.XPATH, \"//a[contains(@class, 'forward') and contains(@class, 'button')]\")\n",
    "        ActionChains(driver).move_to_element(next_link).perform()\n",
    "        next_link.click()\n",
    "        time.sleep(2)\n",
    "        page_number += 1\n",
    "    except:\n",
    "        print(\"‚úÖ Keine weitere Seite gefunden oder Button deaktiviert.\")\n",
    "        break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# === Ordner vorbereiten ===\n",
    "os.makedirs(r\"C:\\Users\\jhummels\\OneDrive - DIW Berlin\\GEHLEN~1\\Data\\BA_data\\A_GEME~1\\ARBEIT~2\", exist_ok=True)\n",
    "failed_links = []\n",
    "\n",
    "# === Hilfsfunktion: Retry-Logik ===\n",
    "def download_with_retries(url, retries=3, delay=5):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=20)\n",
    "            if response.status_code == 200:\n",
    "                return response\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Versuch {i+1} fehlgeschlagen f√ºr {url}: {e}\")\n",
    "            time.sleep(delay)\n",
    "    return None\n",
    "\n",
    "# === PDFs herunterladen ===\n",
    "for link in all_pdf_links:\n",
    "    filename = link.split(\"/\")[-1].split(\"?\")[0].split(\";\")[0]\n",
    "    filename = urllib.parse.unquote(filename)\n",
    "    filepath = os.path.join(r\"C:\\Users\\jhummels\\OneDrive - DIW Berlin\\GEHLEN~1\\Data\\BA_data\\A_GEME~1\\ARBEIT~2\", filename)\n",
    "\n",
    "    # Falls Datei schon existiert, √ºberspringen\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"‚è© √úberspringe bereits vorhandene Datei: {filename}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"‚¨áÔ∏è Lade herunter: {filename}\")\n",
    "    response = download_with_retries(link)\n",
    "    if response:\n",
    "        try:\n",
    "            with open(filepath, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"‚úÖ Erfolgreich gespeichert: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Fehler beim Speichern von {filename}: {e}\")\n",
    "            failed_links.append(link)\n",
    "    else:\n",
    "        print(f\"‚ùå Endg√ºltig fehlgeschlagen: {filename}\")\n",
    "        failed_links.append(link)\n",
    "\n",
    "# === Fehlgeschlagene Links speichern ===\n",
    "if failed_links:\n",
    "    with open(\"failed_pdfs.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for link in failed_links:\n",
    "            f.write(link + \"\\n\")\n",
    "    print(f\"\\n‚ö†Ô∏è {len(failed_links)} Dateien konnten nicht geladen werden. Gespeichert in 'failed_pdfs.txt'\")\n",
    "else:\n",
    "    print(\"\\nüéâ Alle PDFs erfolgreich heruntergeladen!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Step: Read all PDF files and extract relevant tables with the Engpass Indicators, then convert the data into a machine readable format (csv, xlsx)\n",
    "\n",
    "I browse through all pdf files and use the Fitz algorithm from the PyMuPDF to extract the desired table using key words and patterns that detect the right table in the pdf file. In the webscraping for the labor tightness data, I use the camelot package, which is a little bit more advanced when used with the 'network' algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "\n",
    "# Input and output folders\n",
    "input_folder = r\"C:\\Users\\jhummels\\OneDrive - DIW Berlin\\GEHLEN~1\\Data\\BA_data\\A_GEME~1\\ARBEIT~2\"\n",
    "output_folder = r\"C:\\Users\\jhummels\\OneDrive - DIW Berlin\\GEHLEN~1\\Data\\BA_data\\A_GEME~1\\ARBEIT~3\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Table detection pattern\n",
    "pattern = re.compile(\n",
    "    r\"(?P<BKZ>\\d{3})\\s+(?P<Beruf>[\\w√§√∂√º√Ñ√ñ√ú√ü\\-,.()\\/&\\s]+?)\\s+\"\n",
    "    r\"(?P<Zugang>[\\d.]+)\\s+(?P<Zugang_V>[-+.,\\d]+)\\s+\"\n",
    "    r\"(?P<Bestand>[\\d.]+)\\s+(?P<Bestand_V>[-+.,\\d]+)\\s+\"\n",
    "    r\"(?P<Anteil>[\\d.,]+)\\s+(?P<Anteil_V>[-+.,\\d]+)\\s+\"\n",
    "    r\"(?P<Vakanzzeit>[\\d.,]+)\\s+(?P<Vakanzzeit_V>[-+.,\\d]+)\\s+\"\n",
    "    r\"(?P<Arbeitslose>[\\d.]+)\\s+(?P<Arbeitslose_V>[-+.,\\d]+)\\s+\"\n",
    "    r\"(?P<Relation>[\\d.,]+)\\s+(?P<Relation_V>[-+.,\\d]+)\"\n",
    ")\n",
    "\n",
    "# Loop through all PDFs\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(input_folder, filename)\n",
    "        doc = fitz.open(pdf_path)\n",
    "\n",
    "        # Extract text from pages likely to contain the table\n",
    "        text = \"\"\n",
    "        for i, page in enumerate(doc):\n",
    "            page_text = page.get_text()\n",
    "            # Look for BKZ + numeric pattern\n",
    "            if re.search(r\"\\b\\d{3}\\s+[A-Za-z√Ñ√ñ√ú√§√∂√º√ü]\", page_text) and re.search(r\"\\d+\\s+[-+,.0-9]+\\s+\\d+\", page_text):\n",
    "                text += page_text + \"\\n\"\n",
    "\n",
    "        # Match rows using regex\n",
    "        rows = []\n",
    "        for match in pattern.finditer(text):\n",
    "            row = match.groupdict()\n",
    "            for key in row:\n",
    "                row[key] = row[key].replace(\".\", \"\").replace(\",\", \".\") if key != \"Beruf\" else row[key].strip()\n",
    "            rows.append(row)\n",
    "\n",
    "        if rows:\n",
    "            df = pd.DataFrame(rows)\n",
    "            for col in df.columns:\n",
    "                if col != \"Beruf\":\n",
    "                    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "            # Save CSV\n",
    "            output_path = os.path.join(output_folder, os.path.splitext(filename)[0] + \".csv\")\n",
    "            df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "            print(f\"‚úì Saved: {output_path}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No table found in: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge all tables extracted from pdfs into one data frame and add a year and bundesland column based on their file name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Skipping file with unexpected name: combined_arbeitsagentur_data.csv\n",
      "‚úì Combined CSV saved to: C:\\Users\\jhummels\\OneDrive - DIW Berlin\\GEHLEN~1\\Data\\BA_data\\A_GEME~1\\ARBEIT~3\\combined_arbeitsagentur_data.csv\n",
      "‚úì Combined Excel saved to: C:\\Users\\jhummels\\OneDrive - DIW Berlin\\GEHLEN~1\\Data\\BA_data\\A_GEME~1\\ARBEIT~3\\combined_arbeitsagentur_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Folder with individual CSVs\n",
    "csv_folder = r\"C:\\Users\\jhummels\\OneDrive - DIW Berlin\\GEHLEN~1\\Data\\BA_data\\A_GEME~1\\ARBEIT~3\"\n",
    "\n",
    "# List to collect all dataframes\n",
    "all_dfs = []\n",
    "\n",
    "# Regex to extract Bundesland and date info\n",
    "filename_pattern = re.compile(r\"kldb2010-(\\d{2})-0-(\\d{6})\")\n",
    "\n",
    "for file in os.listdir(csv_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        match = filename_pattern.search(file)\n",
    "        if match:\n",
    "            bundesland = match.group(1)\n",
    "            year = match.group(2)[:4]\n",
    "            month = match.group(2)[4:]\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Skipping file with unexpected name: {file}\")\n",
    "            continue\n",
    "\n",
    "        # Load CSV and add metadata\n",
    "        file_path = os.path.join(csv_folder, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df[\"Bundesland\"] = bundesland\n",
    "        df[\"Year\"] = int(year)\n",
    "        df[\"Month\"] = int(month)\n",
    "        all_dfs.append(df)\n",
    "\n",
    "# Merge all\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Export\n",
    "output_csv = os.path.join(csv_folder, \"combined_arbeitsagentur_data.csv\")\n",
    "output_excel = os.path.join(csv_folder, \"combined_arbeitsagentur_data.xlsx\")\n",
    "\n",
    "combined_df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "combined_df.to_excel(output_excel, index=False)\n",
    "\n",
    "print(f\"‚úì Combined CSV saved to: {output_csv}\")\n",
    "print(f\"‚úì Combined Excel saved to: {output_excel}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Clean PDF data frame and get rid of little inaccuracies. Extract BKZ and add as new columns. Delete rows that don't hold any information and rename columns such that the names fit the names of the excel tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BKZ</th>\n",
       "      <th>Beruf</th>\n",
       "      <th>Zugang</th>\n",
       "      <th>Zugang_V</th>\n",
       "      <th>Bestand</th>\n",
       "      <th>Bestand_V</th>\n",
       "      <th>3_Monate_Vakant_Anteil</th>\n",
       "      <th>3_Monate_Vakant_V_abs</th>\n",
       "      <th>abgesch_Vakanzzeit_Tage</th>\n",
       "      <th>abgesch_Vakanzzeit_V_abs</th>\n",
       "      <th>Arbeitslose</th>\n",
       "      <th>Arbeitslose_V</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Relation_V</th>\n",
       "      <th>Bundesland</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>814</td>\n",
       "      <td>Human- und Zahnmedizin</td>\n",
       "      <td>147</td>\n",
       "      <td>10.5</td>\n",
       "      <td>66</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>48.3</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>167</td>\n",
       "      <td>50</td>\n",
       "      <td>93</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>140</td>\n",
       "      <td>-12</td>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>921</td>\n",
       "      <td>Werbung und Marketing</td>\n",
       "      <td>1949</td>\n",
       "      <td>4.2</td>\n",
       "      <td>595</td>\n",
       "      <td>17.4</td>\n",
       "      <td>46.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>113</td>\n",
       "      <td>29</td>\n",
       "      <td>783</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>132</td>\n",
       "      <td>-24</td>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>821</td>\n",
       "      <td>Altenpflege</td>\n",
       "      <td>1644</td>\n",
       "      <td>-13.5</td>\n",
       "      <td>561</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>50.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>110</td>\n",
       "      <td>13</td>\n",
       "      <td>748</td>\n",
       "      <td>-25.4</td>\n",
       "      <td>133</td>\n",
       "      <td>-39</td>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>721</td>\n",
       "      <td>Versicherungs- u. Finanzdienstleistungen</td>\n",
       "      <td>437</td>\n",
       "      <td>6.8</td>\n",
       "      <td>136</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>42.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>102</td>\n",
       "      <td>6</td>\n",
       "      <td>500</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>368</td>\n",
       "      <td>-20</td>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>813</td>\n",
       "      <td>Gesundh.,Krankenpfl.,Rettungsd.Geburtsh.</td>\n",
       "      <td>1563</td>\n",
       "      <td>24.9</td>\n",
       "      <td>453</td>\n",
       "      <td>17.9</td>\n",
       "      <td>38.8</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>87</td>\n",
       "      <td>-17</td>\n",
       "      <td>708</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>156</td>\n",
       "      <td>-40</td>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BKZ                                     Beruf  Zugang  Zugang_V  Bestand  \\\n",
       "2  814                    Human- und Zahnmedizin     147      10.5       66   \n",
       "3  921                     Werbung und Marketing    1949       4.2      595   \n",
       "4  821                               Altenpflege    1644     -13.5      561   \n",
       "5  721  Versicherungs- u. Finanzdienstleistungen     437       6.8      136   \n",
       "6  813  Gesundh.,Krankenpfl.,Rettungsd.Geburtsh.    1563      24.9      453   \n",
       "\n",
       "   Bestand_V  3_Monate_Vakant_Anteil  3_Monate_Vakant_V_abs  \\\n",
       "2       -1.4                    48.3                   -4.7   \n",
       "3       17.4                    46.5                    5.4   \n",
       "4       -3.6                    50.6                    5.3   \n",
       "5       -5.6                    42.8                    1.9   \n",
       "6       17.9                    38.8                   -3.0   \n",
       "\n",
       "   abgesch_Vakanzzeit_Tage  abgesch_Vakanzzeit_V_abs  Arbeitslose  \\\n",
       "2                      167                        50           93   \n",
       "3                      113                        29          783   \n",
       "4                      110                        13          748   \n",
       "5                      102                         6          500   \n",
       "6                       87                       -17          708   \n",
       "\n",
       "   Arbeitslose_V  Relation  Relation_V Bundesland  Year  Month  \n",
       "2           -9.4       140         -12         01  2011     10  \n",
       "3           -1.0       132         -24         01  2011     10  \n",
       "4          -25.4       133         -39         01  2011     10  \n",
       "5          -10.6       368         -20         01  2011     10  \n",
       "6           -6.2       156         -40         01  2011     10  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import relevant libraries: \n",
    "\n",
    "import pandas as pd\n",
    "import re  # <-- Add this\n",
    "\n",
    "data = combined_df.copy()\n",
    "\n",
    "# Show all rows\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "\n",
    "# Optional: also widen column display if needed\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Keep only rows where BKZ is a proper 3-digit number between 100 and 999\n",
    "data = data[data[\"BKZ\"].astype(str).str.fullmatch(r\"\\d{3}\")]\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_clean_bkz_and_beruf(row):\n",
    "    beruf_raw = str(row.get(\"Beruf\", \"\")).replace(\"\\n\", \" \").strip()\n",
    "\n",
    "    # Match pattern like: \"814 Human- und Zahnmedizin\" (ignore any garbage before it)\n",
    "    match = re.search(r\"(\\d{3})\\s+([A-Z√Ñ√ñ√úa-z√§√∂√º√ü].+)\", beruf_raw)\n",
    "    if match:\n",
    "        row[\"BKZ\"] = match.group(1)\n",
    "        row[\"Beruf\"] = match.group(2).strip()\n",
    "    return row\n",
    "\n",
    "data = data.apply(extract_clean_bkz_and_beruf, axis=1)\n",
    "# Keep rows where Beruf starts with a letter (i.e., likely a real label)\n",
    "data = data[\n",
    "    data[\"Beruf\"].notna() &\n",
    "    data[\"Beruf\"].astype(str).str.match(r\"^[A-Z√Ñ√ñ√úa-z√§√∂√º√ü]\")\n",
    "]\n",
    "\n",
    "# Clean up whitespace and hidden characters in all string columns\n",
    "for col in [\"BKZ\", \"Beruf\", \"Bundesland\"]:\n",
    "    data[col] = data[col].astype(str).str.strip().str.replace(r\"\\s+\", \" \", regex=True)\n",
    "data = data.drop_duplicates(subset=[\"BKZ\", \"Beruf\", \"Bundesland\", \"Year\", \"Month\"], keep=\"first\")\n",
    "\n",
    "# Rename columns of PDF data to match column names of the Excel Data \n",
    "\n",
    "data = data.rename(columns={\n",
    "    \"Anteil\": \"3_Monate_Vakant_Anteil\",\n",
    "    \"Anteil_V\" : \"3_Monate_Vakant_V_abs\",\n",
    "    \"Vakanzzeit\" : \"abgesch_Vakanzzeit_Tage\",\n",
    "    \"Vakanzzeit_V\" : \"abgesch_Vakanzzeit_V_abs\"\n",
    "})\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Extract the right tables from all excel files, then clean and improve format of excel data frame, then merge all excel tables into one data frame.\n",
    "\n",
    "I extract the right tables from the excel files by defining the sheet names that include the relevant table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Combined 969 files. Total rows: 58452\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beruf</th>\n",
       "      <th>Zugang</th>\n",
       "      <th>Zugang_V</th>\n",
       "      <th>Bestand</th>\n",
       "      <th>Bestand_V</th>\n",
       "      <th>3_Monate_Vakant_abs</th>\n",
       "      <th>3_Monate_Vakant_V</th>\n",
       "      <th>3_Monate_Vakant_Anteil</th>\n",
       "      <th>3_Monate_Vakant_V_abs</th>\n",
       "      <th>abgesch_Vakanzzeit_Tage</th>\n",
       "      <th>abgesch_Vakanzzeit_V_abs</th>\n",
       "      <th>Arbeitslose</th>\n",
       "      <th>Arbeitslose_V</th>\n",
       "      <th>SGBIII_abs</th>\n",
       "      <th>SGBIII_V</th>\n",
       "      <th>SGBII_abs</th>\n",
       "      <th>SGBII_V</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Relation_V</th>\n",
       "      <th>SGBIII_abs_2</th>\n",
       "      <th>SGBIII_V_2</th>\n",
       "      <th>SGBII_abs_2</th>\n",
       "      <th>SGBII_V_2</th>\n",
       "      <th>BKZ</th>\n",
       "      <th>Bundesland</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Klempnerei,Sanit√§r,Heizung,Klimatechnik</td>\n",
       "      <td>555</td>\n",
       "      <td>-5.290102</td>\n",
       "      <td>374.916667</td>\n",
       "      <td>0.581265</td>\n",
       "      <td>257.333333</td>\n",
       "      <td>0.553566</td>\n",
       "      <td>68.6</td>\n",
       "      <td>-0.018908</td>\n",
       "      <td>211.668508</td>\n",
       "      <td>7.072048</td>\n",
       "      <td>144.666667</td>\n",
       "      <td>-6.816962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.6</td>\n",
       "      <td>-3.063547</td>\n",
       "      <td>65.017411</td>\n",
       "      <td>-2.191057</td>\n",
       "      <td>20.150900</td>\n",
       "      <td>-2.596093</td>\n",
       "      <td>342</td>\n",
       "      <td>01</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>analyse-gemeldete-arbeitsstellen-kldb2010-01-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bau- und Transportger√§tef√ºhrung</td>\n",
       "      <td>111</td>\n",
       "      <td>-31.481481</td>\n",
       "      <td>69.166667</td>\n",
       "      <td>-14.871795</td>\n",
       "      <td>44.916667</td>\n",
       "      <td>-12.924071</td>\n",
       "      <td>64.9</td>\n",
       "      <td>1.452580</td>\n",
       "      <td>210.373913</td>\n",
       "      <td>68.227572</td>\n",
       "      <td>113.750000</td>\n",
       "      <td>-0.582666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.5</td>\n",
       "      <td>23.637319</td>\n",
       "      <td>44.952760</td>\n",
       "      <td>-33.063326</td>\n",
       "      <td>41.819990</td>\n",
       "      <td>-22.154541</td>\n",
       "      <td>525</td>\n",
       "      <td>01</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>analyse-gemeldete-arbeitsstellen-kldb2010-01-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Metallbearbeitung</td>\n",
       "      <td>218</td>\n",
       "      <td>-36.443149</td>\n",
       "      <td>121.416667</td>\n",
       "      <td>-20.512821</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>-7.899807</td>\n",
       "      <td>65.6</td>\n",
       "      <td>8.985798</td>\n",
       "      <td>195.694118</td>\n",
       "      <td>79.882523</td>\n",
       "      <td>234.083333</td>\n",
       "      <td>18.473218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.8</td>\n",
       "      <td>63.442620</td>\n",
       "      <td>100.128507</td>\n",
       "      <td>-4.556622</td>\n",
       "      <td>159.049047</td>\n",
       "      <td>10.092294</td>\n",
       "      <td>242</td>\n",
       "      <td>01</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>analyse-gemeldete-arbeitsstellen-kldb2010-01-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bodenverlegung</td>\n",
       "      <td>224</td>\n",
       "      <td>22.404372</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>1.520159</td>\n",
       "      <td>80.666667</td>\n",
       "      <td>-10.618652</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-8.558810</td>\n",
       "      <td>193.036000</td>\n",
       "      <td>17.831000</td>\n",
       "      <td>90.833333</td>\n",
       "      <td>3.122044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.102339</td>\n",
       "      <td>170.862262</td>\n",
       "      <td>-0.966677</td>\n",
       "      <td>254.669653</td>\n",
       "      <td>13.461432</td>\n",
       "      <td>331</td>\n",
       "      <td>01</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>analyse-gemeldete-arbeitsstellen-kldb2010-01-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Energietechnik</td>\n",
       "      <td>901</td>\n",
       "      <td>-5.157895</td>\n",
       "      <td>514.583333</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>327.166667</td>\n",
       "      <td>4.276228</td>\n",
       "      <td>63.6</td>\n",
       "      <td>2.039229</td>\n",
       "      <td>189.345251</td>\n",
       "      <td>14.621151</td>\n",
       "      <td>289.333333</td>\n",
       "      <td>9.423259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.2</td>\n",
       "      <td>4.363367</td>\n",
       "      <td>268.888889</td>\n",
       "      <td>18.445203</td>\n",
       "      <td>150.222222</td>\n",
       "      <td>-4.385286</td>\n",
       "      <td>262</td>\n",
       "      <td>01</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>analyse-gemeldete-arbeitsstellen-kldb2010-01-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Beruf  Zugang   Zugang_V     Bestand  \\\n",
       "0  Klempnerei,Sanit√§r,Heizung,Klimatechnik     555  -5.290102  374.916667   \n",
       "1          Bau- und Transportger√§tef√ºhrung     111 -31.481481   69.166667   \n",
       "2                        Metallbearbeitung     218 -36.443149  121.416667   \n",
       "3                           Bodenverlegung     224  22.404372  128.000000   \n",
       "4                           Energietechnik     901  -5.157895  514.583333   \n",
       "\n",
       "   Bestand_V  3_Monate_Vakant_abs  3_Monate_Vakant_V  3_Monate_Vakant_Anteil  \\\n",
       "0   0.581265           257.333333           0.553566                    68.6   \n",
       "1 -14.871795            44.916667         -12.924071                    64.9   \n",
       "2 -20.512821            79.666667          -7.899807                    65.6   \n",
       "3   1.520159            80.666667         -10.618652                    63.0   \n",
       "4   0.931677           327.166667           4.276228                    63.6   \n",
       "\n",
       "   3_Monate_Vakant_V_abs  abgesch_Vakanzzeit_Tage  abgesch_Vakanzzeit_V_abs  \\\n",
       "0              -0.018908               211.668508                  7.072048   \n",
       "1               1.452580               210.373913                 68.227572   \n",
       "2               8.985798               195.694118                 79.882523   \n",
       "3              -8.558810               193.036000                 17.831000   \n",
       "4               2.039229               189.345251                 14.621151   \n",
       "\n",
       "   Arbeitslose  Arbeitslose_V  SGBIII_abs  SGBIII_V  SGBII_abs  SGBII_V  \\\n",
       "0   144.666667      -6.816962         NaN       NaN        NaN      NaN   \n",
       "1   113.750000      -0.582666         NaN       NaN        NaN      NaN   \n",
       "2   234.083333      18.473218         NaN       NaN        NaN      NaN   \n",
       "3    90.833333       3.122044         NaN       NaN        NaN      NaN   \n",
       "4   289.333333       9.423259         NaN       NaN        NaN      NaN   \n",
       "\n",
       "   Relation  Relation_V  SGBIII_abs_2  SGBIII_V_2  SGBII_abs_2  SGBII_V_2  \\\n",
       "0      38.6   -3.063547     65.017411   -2.191057    20.150900  -2.596093   \n",
       "1     164.5   23.637319     44.952760  -33.063326    41.819990 -22.154541   \n",
       "2     192.8   63.442620    100.128507   -4.556622   159.049047  10.092294   \n",
       "3      71.0    1.102339    170.862262   -0.966677   254.669653  13.461432   \n",
       "4      56.2    4.363367    268.888889   18.445203   150.222222  -4.385286   \n",
       "\n",
       "   BKZ Bundesland  Year  Month  \\\n",
       "0  342         01  2020      2   \n",
       "1  525         01  2020      2   \n",
       "2  242         01  2020      2   \n",
       "3  331         01  2020      2   \n",
       "4  262         01  2020      2   \n",
       "\n",
       "                                         source_file  \n",
       "0  analyse-gemeldete-arbeitsstellen-kldb2010-01-0...  \n",
       "1  analyse-gemeldete-arbeitsstellen-kldb2010-01-0...  \n",
       "2  analyse-gemeldete-arbeitsstellen-kldb2010-01-0...  \n",
       "3  analyse-gemeldete-arbeitsstellen-kldb2010-01-0...  \n",
       "4  analyse-gemeldete-arbeitsstellen-kldb2010-01-0...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load relevant libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Path to folder with Excel files\n",
    "excel_folder = r\"C:\\Users\\jhummels\\OneDrive - DIW Berlin\\GEHLEN~1\\Data\\BA_data\\A_GEME~1\\ARBEIT~1\"\n",
    "\n",
    "# Collect cleaned DataFrames\n",
    "all_dfs = []\n",
    "\n",
    "# Loop through Excel files\n",
    "for file in os.listdir(excel_folder):\n",
    "    if file.endswith(\".xlsx\"):\n",
    "        filepath = os.path.join(excel_folder, file)\n",
    "        try:\n",
    "            # Load the sheet (header on row 7)\n",
    "            df = pd.read_excel(filepath, sheet_name=\"3.1 Engpass_Tab1\", header=7)\n",
    "\n",
    "            # Drop last 4 columns\n",
    "            df = df.iloc[:, :-4]\n",
    "\n",
    "            # Rename columns (up to 24)\n",
    "            df.columns = [\n",
    "             \"Drop\", \"Beruf\",\n",
    "             \"Zugang\", \"Zugang_V\",\n",
    "             \"Bestand\", \"Bestand_V\",\n",
    "             \"3_Monate_Vakant_abs\", \"3_Monate_Vakant_V\",\n",
    "             \"3_Monate_Vakant_Anteil\", \"3_Monate_Vakant_V_abs\",\n",
    "             \"abgesch_Vakanzzeit_Tage\", \"abgesch_Vakanzzeit_V_abs\",\n",
    "             \"Arbeitslose\", \"Arbeitslose_V\",\n",
    "             \"SGBIII_abs\", \"SGBIII_V\",\n",
    "             \"SGBII_abs\", \"SGBII_V\",\n",
    "             \"Relation\", \"Relation_V\",\n",
    "             \"SGBIII_abs_2\", \"SGBIII_V_2\",\n",
    "             \"SGBII_abs_2\", \"SGBII_V_2\"\n",
    "            ]\n",
    "\n",
    "            # Drop the first column (empty)\n",
    "            df = df.drop(columns=\"Drop\")\n",
    "\n",
    "            # Remove footer or malformed rows\n",
    "            df = df[df[\"Beruf\"].astype(str).str.match(r\"^\\d{3}\\s+.+\")]\n",
    "\n",
    "            # Split BKZ from Beruf\n",
    "            df[[\"BKZ\", \"Beruf\"]] = df[\"Beruf\"].str.extract(r\"^(\\d{3})\\s+(.+)$\")\n",
    "\n",
    "            # Convert numeric columns\n",
    "            numeric_cols = [col for col in df.columns if col not in [\"Beruf\", \"BKZ\"] and df[col].ndim == 1]\n",
    "            for col in numeric_cols:\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "            # Drop \"Insgesamt\" row if present\n",
    "            df = df[~df.iloc[:, 1].astype(str).str.contains(\"Insgesamt\", na=False)]\n",
    "\n",
    "            # Add metadata from filename\n",
    "            match = re.search(r\"kldb2010-(\\d{2})-0-(\\d{6})\", file)\n",
    "            if match:\n",
    "                df[\"Bundesland\"] = match.group(1)\n",
    "                df[\"Year\"] = int(match.group(2)[:4])\n",
    "                df[\"Month\"] = int(match.group(2)[4:])\n",
    "            else:\n",
    "                df[\"Bundesland\"] = df[\"Year\"] = df[\"Month\"] = None\n",
    "\n",
    "            df[\"source_file\"] = file\n",
    "\n",
    "            all_dfs.append(df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {file}: {e}\")\n",
    "\n",
    "# Combine all cleaned data\n",
    "combined_excel_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Preview\n",
    "print(f\"‚úì Combined {len(all_dfs)} files. Total rows: {combined_excel_df.shape[0]}\")\n",
    "combined_excel_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview of the excel data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_excel_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inquiry of NA count for the webscraped PDF and Excel Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isna().sum())\n",
    "print(combined_excel_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGBIII_abs, SGBIII_V, SGBII_abs, SGBII_V all have 59452 missing values (which are all rows), so we can drop them without any bad conscience "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_excel_df = combined_excel_df.drop(columns=[\n",
    "    \"SGBIII_abs\", \"SGBIII_V\", \"SGBII_abs\", \"SGBII_V\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging PDF and Excel data frames into one data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149419, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beruf</th>\n",
       "      <th>Zugang</th>\n",
       "      <th>Zugang_V</th>\n",
       "      <th>Bestand</th>\n",
       "      <th>Bestand_V</th>\n",
       "      <th>3_Monate_Vakant_abs</th>\n",
       "      <th>3_Monate_Vakant_V</th>\n",
       "      <th>3_Monate_Vakant_Anteil</th>\n",
       "      <th>3_Monate_Vakant_V_abs</th>\n",
       "      <th>abgesch_Vakanzzeit_Tage</th>\n",
       "      <th>abgesch_Vakanzzeit_V_abs</th>\n",
       "      <th>Arbeitslose</th>\n",
       "      <th>Arbeitslose_V</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Relation_V</th>\n",
       "      <th>SGBIII_abs_2</th>\n",
       "      <th>SGBIII_V_2</th>\n",
       "      <th>SGBII_abs_2</th>\n",
       "      <th>SGBII_V_2</th>\n",
       "      <th>BKZ</th>\n",
       "      <th>Bundesland</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human- und Zahnmedizin</td>\n",
       "      <td>147</td>\n",
       "      <td>10.5</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.3</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>167.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>814</td>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Werbung und Marketing</td>\n",
       "      <td>1949</td>\n",
       "      <td>4.2</td>\n",
       "      <td>595.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>921</td>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Altenpflege</td>\n",
       "      <td>1644</td>\n",
       "      <td>-13.5</td>\n",
       "      <td>561.0</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>-25.4</td>\n",
       "      <td>133.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>821</td>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Versicherungs- u. Finanzdienstleistungen</td>\n",
       "      <td>437</td>\n",
       "      <td>6.8</td>\n",
       "      <td>136.0</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>102.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>368.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>721</td>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gesundh.,Krankenpfl.,Rettungsd.Geburtsh.</td>\n",
       "      <td>1563</td>\n",
       "      <td>24.9</td>\n",
       "      <td>453.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.8</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>156.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>813</td>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Beruf  Zugang  Zugang_V  Bestand  \\\n",
       "0                    Human- und Zahnmedizin     147      10.5     66.0   \n",
       "1                     Werbung und Marketing    1949       4.2    595.0   \n",
       "2                               Altenpflege    1644     -13.5    561.0   \n",
       "3  Versicherungs- u. Finanzdienstleistungen     437       6.8    136.0   \n",
       "4  Gesundh.,Krankenpfl.,Rettungsd.Geburtsh.    1563      24.9    453.0   \n",
       "\n",
       "   Bestand_V  3_Monate_Vakant_abs  3_Monate_Vakant_V  3_Monate_Vakant_Anteil  \\\n",
       "0       -1.4                  NaN                NaN                    48.3   \n",
       "1       17.4                  NaN                NaN                    46.5   \n",
       "2       -3.6                  NaN                NaN                    50.6   \n",
       "3       -5.6                  NaN                NaN                    42.8   \n",
       "4       17.9                  NaN                NaN                    38.8   \n",
       "\n",
       "   3_Monate_Vakant_V_abs  abgesch_Vakanzzeit_Tage  abgesch_Vakanzzeit_V_abs  \\\n",
       "0                   -4.7                    167.0                      50.0   \n",
       "1                    5.4                    113.0                      29.0   \n",
       "2                    5.3                    110.0                      13.0   \n",
       "3                    1.9                    102.0                       6.0   \n",
       "4                   -3.0                     87.0                     -17.0   \n",
       "\n",
       "   Arbeitslose  Arbeitslose_V  Relation  Relation_V  SGBIII_abs_2  SGBIII_V_2  \\\n",
       "0         93.0           -9.4     140.0       -12.0           NaN         NaN   \n",
       "1        783.0           -1.0     132.0       -24.0           NaN         NaN   \n",
       "2        748.0          -25.4     133.0       -39.0           NaN         NaN   \n",
       "3        500.0          -10.6     368.0       -20.0           NaN         NaN   \n",
       "4        708.0           -6.2     156.0       -40.0           NaN         NaN   \n",
       "\n",
       "   SGBII_abs_2  SGBII_V_2  BKZ Bundesland  Year  Month source_file  \n",
       "0          NaN        NaN  814         01  2011     10         NaN  \n",
       "1          NaN        NaN  921         01  2011     10         NaN  \n",
       "2          NaN        NaN  821         01  2011     10         NaN  \n",
       "3          NaN        NaN  721         01  2011     10         NaN  \n",
       "4          NaN        NaN  813         01  2011     10         NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Reindex `data` to match the column structure of `combined_excel_df`\n",
    "data_aligned = data.reindex(columns=combined_excel_df.columns)\n",
    "\n",
    "# Append older `data` before `combined_excel_df`\n",
    "full_df = pd.concat([data_aligned, combined_excel_df], ignore_index=True)\n",
    "\n",
    "# Preview result\n",
    "print(full_df.shape)\n",
    "full_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve column names and order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bundesland</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>BKZ</th>\n",
       "      <th>Beruf</th>\n",
       "      <th>Zugang</th>\n",
       "      <th>Zugang_V</th>\n",
       "      <th>Bestand</th>\n",
       "      <th>Bestand_V</th>\n",
       "      <th>3_Monate_Vakant_abs</th>\n",
       "      <th>3_Monate_Vakant_V</th>\n",
       "      <th>3_Monate_Vakant_Anteil</th>\n",
       "      <th>3_Monate_Vakant_V_abs</th>\n",
       "      <th>abgesch_Vakanzzeit_Tage</th>\n",
       "      <th>abgesch_Vakanzzeit_V_abs</th>\n",
       "      <th>Arbeitslose</th>\n",
       "      <th>Arbeitslose_V</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Relation_V</th>\n",
       "      <th>SGBIII_abs_2</th>\n",
       "      <th>SGBIII_V_2</th>\n",
       "      <th>SGBII_abs_2</th>\n",
       "      <th>SGBII_V_2</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>814</td>\n",
       "      <td>Human- und Zahnmedizin</td>\n",
       "      <td>147</td>\n",
       "      <td>10.5</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.3</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>167.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>921</td>\n",
       "      <td>Werbung und Marketing</td>\n",
       "      <td>1949</td>\n",
       "      <td>4.2</td>\n",
       "      <td>595.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>821</td>\n",
       "      <td>Altenpflege</td>\n",
       "      <td>1644</td>\n",
       "      <td>-13.5</td>\n",
       "      <td>561.0</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>-25.4</td>\n",
       "      <td>133.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>721</td>\n",
       "      <td>Versicherungs- u. Finanzdienstleistungen</td>\n",
       "      <td>437</td>\n",
       "      <td>6.8</td>\n",
       "      <td>136.0</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>102.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>368.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>813</td>\n",
       "      <td>Gesundh.,Krankenpfl.,Rettungsd.Geburtsh.</td>\n",
       "      <td>1563</td>\n",
       "      <td>24.9</td>\n",
       "      <td>453.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.8</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>156.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Bundesland  Year  Month  BKZ                                     Beruf  \\\n",
       "0         01  2011     10  814                    Human- und Zahnmedizin   \n",
       "1         01  2011     10  921                     Werbung und Marketing   \n",
       "2         01  2011     10  821                               Altenpflege   \n",
       "3         01  2011     10  721  Versicherungs- u. Finanzdienstleistungen   \n",
       "4         01  2011     10  813  Gesundh.,Krankenpfl.,Rettungsd.Geburtsh.   \n",
       "\n",
       "   Zugang  Zugang_V  Bestand  Bestand_V  3_Monate_Vakant_abs  \\\n",
       "0     147      10.5     66.0       -1.4                  NaN   \n",
       "1    1949       4.2    595.0       17.4                  NaN   \n",
       "2    1644     -13.5    561.0       -3.6                  NaN   \n",
       "3     437       6.8    136.0       -5.6                  NaN   \n",
       "4    1563      24.9    453.0       17.9                  NaN   \n",
       "\n",
       "   3_Monate_Vakant_V  3_Monate_Vakant_Anteil  3_Monate_Vakant_V_abs  \\\n",
       "0                NaN                    48.3                   -4.7   \n",
       "1                NaN                    46.5                    5.4   \n",
       "2                NaN                    50.6                    5.3   \n",
       "3                NaN                    42.8                    1.9   \n",
       "4                NaN                    38.8                   -3.0   \n",
       "\n",
       "   abgesch_Vakanzzeit_Tage  abgesch_Vakanzzeit_V_abs  Arbeitslose  \\\n",
       "0                    167.0                      50.0         93.0   \n",
       "1                    113.0                      29.0        783.0   \n",
       "2                    110.0                      13.0        748.0   \n",
       "3                    102.0                       6.0        500.0   \n",
       "4                     87.0                     -17.0        708.0   \n",
       "\n",
       "   Arbeitslose_V  Relation  Relation_V  SGBIII_abs_2  SGBIII_V_2  SGBII_abs_2  \\\n",
       "0           -9.4     140.0       -12.0           NaN         NaN          NaN   \n",
       "1           -1.0     132.0       -24.0           NaN         NaN          NaN   \n",
       "2          -25.4     133.0       -39.0           NaN         NaN          NaN   \n",
       "3          -10.6     368.0       -20.0           NaN         NaN          NaN   \n",
       "4           -6.2     156.0       -40.0           NaN         NaN          NaN   \n",
       "\n",
       "   SGBII_V_2 source_file  \n",
       "0        NaN         NaN  \n",
       "1        NaN         NaN  \n",
       "2        NaN         NaN  \n",
       "3        NaN         NaN  \n",
       "4        NaN         NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjust column names in a better order\n",
    "\n",
    "\n",
    "desired_order = [\n",
    "    'Bundesland', 'Year', 'Month',\n",
    "    'BKZ', 'Beruf',\n",
    "    'Zugang', 'Zugang_V',\n",
    "    'Bestand', 'Bestand_V',\n",
    "    '3_Monate_Vakant_abs', '3_Monate_Vakant_V',\n",
    "    '3_Monate_Vakant_Anteil', '3_Monate_Vakant_V_abs',\n",
    "    'abgesch_Vakanzzeit_Tage', 'abgesch_Vakanzzeit_V_abs',\n",
    "    'Arbeitslose', 'Arbeitslose_V',\n",
    "    'Relation', 'Relation_V',\n",
    "    'SGBIII_abs_2', 'SGBIII_V_2',\n",
    "    'SGBII_abs_2', 'SGBII_V_2',\n",
    "    'source_file'\n",
    "]\n",
    "\n",
    "# Keep only the columns that are actually in the DataFrame\n",
    "existing_columns = [col for col in desired_order if col in full_df.columns]\n",
    "\n",
    "# Reorder\n",
    "full_df = full_df[existing_columns]\n",
    "\n",
    "\n",
    "full_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the full data frame of all webscraped data for Arbeitsstellen nach Berufsgruppen into an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv(r\"C:\\Users\\jhummels\\OneDrive - DIW Berlin\\GEHLEN~1\\Data\\BA_data\\A_GEME~1\\Merged_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
